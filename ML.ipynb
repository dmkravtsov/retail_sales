{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oftuadmin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1067\n",
      "[LightGBM] [Info] Number of data points in the train set: 653077, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 1437.538380\n",
      "MSE: 5126453.201285902, R2: 0.6118902534368351\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "SEED = 2020\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df['has_promo'] = df['has_promo'].astype(int)\n",
    "\n",
    "# 2. Compute the revenue\n",
    "df['revenue'] = df['sales'] * (df['shelf_price'] - df['shelf_price'] * df['discount_percent'])\n",
    "# df['log_revenue'] = df['revenue'].apply(lambda x: np.log(x) if x > 0 else 0)\n",
    "\n",
    "\n",
    "# 3. Determine the weight for each class based on the inverse proportion of its occurrence\n",
    "class_proportions = df['has_promo'].value_counts(normalize=True)\n",
    "weights_map = 1 / class_proportions\n",
    "weights = df['has_promo'].map(weights_map)\n",
    "\n",
    "# 4. Features and Target\n",
    "features = ['store_cluster_id', 'shelf_price', 'has_promo', 'category_1', 'category_2', 'category_3', 'category_3_promo_coverage', 'discount_percent']\n",
    "target = 'revenue'\n",
    "\n",
    "# 5. Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=SEED)\n",
    "\n",
    "# 6. LGBM parameters\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.6,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'max_bin': 255,\n",
    "    'subsample': 0.9,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'min_child_weight': 0,\n",
    "    'min_split_gain': 0,\n",
    "    'subsample_for_bin': 200000,\n",
    "}\n",
    "\n",
    "# 7. Weights for train data\n",
    "train_weights = weights.loc[X_train.index]\n",
    "\n",
    "# 8. Create datasets for LGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train, weight=train_weights)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# 8. Model Training\n",
    "bst = lgb.train(params, train_data, 500, valid_sets=[test_data], verbose_eval=-1)\n",
    "\n",
    "# 10. Predictions\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# 11. Model Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oftuadmin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1063\n",
      "[LightGBM] [Info] Number of data points in the train set: 115769, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 1429.264099\n",
      "MSE: 5815862.066026874, R2: 0.703393098914938\n"
     ]
    }
   ],
   "source": [
    "# Balancing the dataset by values has_promo\n",
    "df_promo = df[df['has_promo'] == 1]\n",
    "df_no_promo = df[df['has_promo'] == 0].sample(len(df_promo))\n",
    "df_balanced = pd.concat([df_promo, df_no_promo])\n",
    "\n",
    "\n",
    "# Параметры модели\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.33,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': -1,\n",
    "    'min_child_samples': 20,\n",
    "    'max_bin': 255,\n",
    "    'subsample': 0.9,\n",
    "    'subsample_freq': 1,\n",
    "    'colsample_bytree': 0.9,\n",
    "    'min_child_weight': 0,\n",
    "    'min_split_gain': 0,\n",
    "    'subsample_for_bin': 200000,\n",
    "}\n",
    "\n",
    "# Разбиваем данные на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced[features], df_balanced[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем датасеты для LGB\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "# Обучение модели\n",
    "bst = lgb.train(params, train_data, 500, valid_sets=[test_data], verbose_eval=-1)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "# Оценка качества модели\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}, R2: {r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "This code is designed to predict the revenue from product sales based on various features using the LightGBM machine learning model. The dataset comprises historical data on retail sales, prices, and discounts. The main steps include data loading, revenue computation, feature engineering, model training, and evaluation. The target variable is the computed 'revenue', while the features include product details, store details, and promotional information.\n",
    "\n",
    "The model's performance is evaluated using the Mean Squared Error (MSE) and R^2 metrics. Additionally, to address the class imbalance in the has_promo feature, inverse proportion weights are calculated and applied during model training. This helps in giving more importance to the underrepresented class and improving the model's generalization capability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaches to Balancing the Dataset for Model Training\n",
    "\n",
    "In our efforts to train a machine learning model to predict revenue based on various product attributes, we encountered an imbalance in our dataset with respect to the has_promo attribute. This attribute indicates whether a product had a promotion or not. Addressing this imbalance is crucial to ensure our model provides reliable predictions.\n",
    "\n",
    "1. Weighted Loss Function Approach:\n",
    "The first method we employed was to assign different weights to the classes in the has_promo attribute. This allows the model to give more importance to under-represented classes during training. The weights were inversely proportional to the class frequencies, meaning the less frequent class got a higher weight.\n",
    "\n",
    "2. Resampling Approach:\n",
    "The second method involved balancing the dataset by resampling. We created two subsets of the data: one with has_promo equal to 1 and another equal to 0. From the larger subset, we randomly sampled instances to match the size of the smaller subset, ensuring an equal number of instances for both promo and non-promo products. The model was then trained on this balanced dataset.\n",
    "\n",
    "Comparison and Conclusion:\n",
    "Upon comparing the performance of models trained with both methods, the resampling approach (the second method) yielded better results in terms of the R^2 metric. This suggests that, for our specific dataset and problem, creating a balanced dataset through resampling was more effective than using a weighted loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>discount_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  discount_best\n",
       "0           0           10.0\n",
       "1           1            0.0\n",
       "2           2           10.0\n",
       "3           3            0.0\n",
       "4           4            0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potential discount levels\n",
    "discount_levels = [0, 0.03, 0.05, 0.07, 0.1, 0.2, 0.5]\n",
    "\n",
    "# Prepare an empty list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate through each product in the dataset\n",
    "for product in df['product_id'].unique():\n",
    "    \n",
    "    product_data = df[df['product_id'] == product].copy()\n",
    "    \n",
    "    max_revenue = -np.inf\n",
    "    best_discount = 0\n",
    "    \n",
    "    # Iterate through each potential discount level\n",
    "    for discount in discount_levels:\n",
    "        \n",
    "        # Set the discount level and adjust the 'has_promo' attribute\n",
    "        product_data['discount_percent'] = discount\n",
    "        product_data['has_promo'] = 1 if discount > 0 else 0\n",
    "        \n",
    "        # Predict the revenue at this discount level\n",
    "        predicted_revenue = np.sum(bst.predict(product_data[features]))\n",
    "        \n",
    "        # Check if this discount level gives a higher revenue than previous ones\n",
    "        if predicted_revenue > max_revenue:\n",
    "            max_revenue = predicted_revenue\n",
    "            best_discount = discount\n",
    "    \n",
    "    # Append the results\n",
    "    results.append({'product_id': product, 'discount_best': best_discount * 100})\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "discount_df = pd.DataFrame(results)\n",
    "\n",
    "discount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>discount_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10110</th>\n",
       "      <td>10110</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>6880</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6485</th>\n",
       "      <td>6485</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>10789</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>1348</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1286</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>9739</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7738</th>\n",
       "      <td>7738</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>4460</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  discount_best\n",
       "10110       10110           50.0\n",
       "6880         6880           50.0\n",
       "39             39            0.0\n",
       "6485         6485            7.0\n",
       "10789       10789           20.0\n",
       "1348         1348           50.0\n",
       "1286         1286           50.0\n",
       "9739         9739           50.0\n",
       "7738         7738           50.0\n",
       "4460         4460            3.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_df.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing Discount Levels for Products\n",
    "\n",
    "In the second phase of our approach, we sought to determine the optimal discount level for each product to maximize revenue. Here's what we did:\n",
    "\n",
    "Potential Discount Levels:\n",
    "\n",
    "We predefined a set of potential discount levels: 0%, 3%, 5%, 7%, 10%, 20%, and 50%.\n",
    "Iterative Testing for Each Product:\n",
    "\n",
    "For each unique product in our dataset, we iteratively applied each potential discount level.\n",
    "Modified the dataset to reflect this discount and adjusted the has_promo attribute accordingly.\n",
    "Revenue Prediction:\n",
    "\n",
    "For each applied discount level, we utilized our trained machine learning model to predict the expected revenue for that product.\n",
    "Selecting the Optimal Discount:\n",
    "\n",
    "We compared the predicted revenues across all discount levels for each product.\n",
    "Chose the discount level that maximized the predicted revenue as the optimal discount for that product.\n",
    "Final Dataset:\n",
    "\n",
    "Compiled a dataset, discount_df, containing each product's ID and its corresponding optimal discount level.\n",
    "Through this process, we now have a recommendation for the best discount level for each product, aimed at maximizing the revenue based on our model's predictions. This methodology allows us to make data-driven decisions on discounting strategies for each product in the inventory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
